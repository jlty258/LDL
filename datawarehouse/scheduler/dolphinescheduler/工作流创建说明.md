# DolphinScheduler 工作流创建说明

## 当前状态

### ✅ 已完成
1. **JSON 工作流定义文件已生成** - 15 个工作流 JSON 文件已生成在 `workflow_definitions/` 目录
2. **PyDolphinScheduler 已安装** - 版本 4.1.0 已集成到容器中
3. **环境变量已配置** - docker-compose.yml 中已配置相关环境变量
4. **Java Gateway 已配置** - 端口 25333 已暴露，环境变量已设置，连接测试通过 ✅
5. **30 个工作流已创建** - 所有工作流已通过 PyDolphinScheduler 创建 ✅
6. **工作流调度已配置** - 所有工作流已配置定时调度 ✅

### ⚠️ 当前限制
- **版本警告**: PyDolphinScheduler 4.1.0 与 Java Gateway (dev-SNAPSHOT) 版本不匹配，但功能正常

## 推荐方案：使用 JSON 文件导入

### 步骤 1: 确认 JSON 文件已生成

JSON 文件位置：`/workspace/datawarehouse/schedulers/workflow_definitions/`

已生成的工作流：
- ODS 层：5 个工作流
- DWD 层：4 个工作流  
- DWS 层：3 个工作流
- ADS 层：3 个工作流

### 步骤 2: 在 DolphinScheduler Web UI 中导入

1. **登录 DolphinScheduler Web UI**
   - 访问：http://dolphinscheduler:12345（容器网络）或 http://localhost:12345（宿主机）
   - 用户名：admin
   - 密码：dolphinscheduler123

2. **创建项目**（如果不存在）
   - 进入"项目管理"
   - 创建项目："制造业数仓"

3. **导入工作流**
   - 进入项目："制造业数仓"
   - 点击"工作流定义" -> "导入工作流"
   - 选择 JSON 文件并导入

### 步骤 3: 配置数据源

在导入工作流之前，需要先配置数据源：
1. 进入"数据源中心"
2. 创建 MySQL 数据源
3. 记录数据源 ID（默认使用 ID=1）

## ✅ 使用 PyDolphinScheduler 创建工作流和调度（已完成）

### 当前状态
- ✅ **30 个工作流已创建** - 所有工作流已通过 PyDolphinScheduler 创建
- ✅ **调度已配置** - 所有工作流已配置定时调度：
  - ODS 层：每天凌晨 2 点 (`0 0 2 * * ?`)
  - DWD 层：每天凌晨 3 点 (`0 0 3 * * ?`)
  - DWS 层：每天凌晨 4 点 (`0 0 4 * * ?`)
  - ADS 层：每天凌晨 5 点 (`0 0 5 * * ?`)

### 使用方法

#### 创建工作流并配置调度

```python
from pydolphinscheduler_client import get_client_from_env

client = get_client_from_env()

# 创建工作流并设置调度
success = client.create_sql_workflow_from_file(
    workflow_name="ods_01_order_master_etl",
    description="ODS层-订单主表ETL",
    sql_file="02_ods_tables.sql",
    schedule="0 0 2 * * ?",  # 每天凌晨2点执行
    datasource_name="MySQL",
    datasource_id=1
)
```

#### 批量创建工作流和调度

运行脚本：
```bash
docker exec python-scripts python /workspace/datawarehouse/schedulers/create_schedules_pyds.py
```

### 注意事项

1. **Cron 格式**：PyDolphinScheduler 4.1.0 需要 7 字段格式（包含年份），但客户端会自动转换 6 字段格式
2. **start_time 和 end_time**：客户端会自动设置开始时间和结束时间
3. **工作流覆盖**：如果工作流已存在，重新创建会覆盖现有工作流

## 备选方案：配置 Java Gateway（高级）

如果需要使用 PyDolphinScheduler 自动创建工作流，需要配置 Java Gateway：

### 1. 检查 DolphinScheduler 是否支持 Java Gateway

```bash
# 检查 DolphinScheduler 容器
docker ps | grep dolphinscheduler
```

### 2. 配置 Java Gateway 环境变量

在 docker-compose.yml 中添加：

```yaml
environment:
  - PYDS_JAVA_GATEWAY_ADDRESS=dolphinscheduler
  - PYDS_JAVA_GATEWAY_PORT=25333
```

### 3. 确保 Java Gateway 服务运行

Java Gateway 通常集成在 DolphinScheduler 中，需要确保：
- DolphinScheduler 服务正常运行
- Java Gateway 端口（默认 25333）可访问

## 快速开始（JSON 导入方式）

### 在容器中查看生成的 JSON 文件

```bash
# 进入容器
docker exec -it python-scripts bash

# 查看生成的 JSON 文件
ls -la /workspace/datawarehouse/schedulers/workflow_definitions/

# 查看某个 JSON 文件内容
cat /workspace/datawarehouse/schedulers/workflow_definitions/ods_01_order_etl.json
```

### 从宿主机访问 JSON 文件

JSON 文件位置：`d:\LDL\datawarehouse\schedulers\workflow_definitions\`

## 工作流列表

### ODS 层（操作数据存储层）
1. `ods_01_order_etl.json` - 订单数据ETL
2. `ods_02_production_etl.json` - 生产数据ETL
3. `ods_03_inventory_etl.json` - 库存数据ETL
4. `ods_04_purchase_etl.json` - 采购数据ETL
5. `ods_05_quality_etl.json` - 质量数据ETL

### DWD 层（数据仓库明细层）
1. `dwd_01_order_fact_etl.json` - 订单事实表ETL
2. `dwd_02_production_fact_etl.json` - 生产事实表ETL
3. `dwd_03_inventory_fact_etl.json` - 库存事实表ETL
4. `dwd_04_purchase_fact_etl.json` - 采购事实表ETL

### DWS 层（数据仓库汇总层）
1. `dws_01_order_daily_etl.json` - 订单日汇总ETL
2. `dws_02_production_daily_etl.json` - 生产日汇总ETL
3. `dws_03_inventory_daily_etl.json` - 库存日汇总ETL

### ADS 层（应用数据服务层）
1. `ads_01_sales_analysis_etl.json` - 销售分析报表ETL
2. `ads_02_production_analysis_etl.json` - 生产分析报表ETL
3. `ads_03_business_overview_etl.json` - 综合经营分析报表ETL

## 注意事项

1. **数据源配置**：导入工作流前，确保在 DolphinScheduler 中已配置 MySQL 数据源
2. **项目创建**：确保项目"制造业数仓"已存在
3. **调度配置**：导入后，可以在 Web UI 中调整每个工作流的调度时间
4. **SQL 内容**：JSON 文件中的 SQL 可能需要根据实际环境调整

## 故障排查

### 问题：JSON 文件导入失败
- 检查 JSON 文件格式是否正确
- 确认项目已创建
- 检查数据源是否配置

### 问题：工作流执行失败
- 检查数据源连接是否正常
- 确认 SQL 语句是否正确
- 查看 DolphinScheduler 日志

## 下一步

1. ✅ JSON 文件已生成
2. ⏳ 在 Web UI 中导入工作流
3. ⏳ 配置数据源
4. ⏳ 测试工作流执行
